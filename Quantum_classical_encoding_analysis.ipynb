{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55G-2rCHOlqB"
      },
      "source": [
        "# **This is a notebook to experiment the different embedding techniques and their effects on the classification task for intrusion detection**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzOkKgn2PT1g"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "\n",
        "!pip install pennylane\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R7B74qWGUse"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEWtsUv2rojj"
      },
      "outputs": [],
      "source": [
        "#This section imports the data as a dataframe\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Dataset_Quantum/Cleaned_EdgeIoT.csv' #data file from drive folder\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "df = df.drop('Unnamed: 0',axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H7ndKAAnM2q"
      },
      "source": [
        "Basic configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tlf6LvR3nIRR"
      },
      "outputs": [],
      "source": [
        "################################################### Aymene's ##########################################\n",
        "# Define the number of qubits\n",
        "n_qubits = 8\n",
        "# Define the feature size\n",
        "n_features = 8\n",
        "\n",
        "# Step 1: Create a quantum device with 5 qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol14YsfXqNSB"
      },
      "source": [
        "The following code:\n",
        "- Retrieve split the data from the labels\n",
        "- Split the train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_CTlHrDqJtl"
      },
      "outputs": [],
      "source": [
        "# Use X for the data and y for the label\n",
        "# prompt: Prends le dataset en haut et garde les 8 features ayant le plus haut score sur XGBoost.\n",
        "\n",
        "\n",
        "\n",
        "# Assuming your target variable is named 'target'\n",
        "X = df.drop('Attack_label', axis=1)\n",
        "y = df['Attack_label']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to store feature importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort the DataFrame by importance in descending order\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Get the top 8 features\n",
        "top_features = feature_importance_df['Feature'].head(30).tolist()\n",
        "\n",
        "\n",
        "\n",
        "Features = top_features\n",
        "X = df[Features[:n_features]]\n",
        "\n",
        "y = df['Attack_label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhTvO2t4S5Gj"
      },
      "source": [
        "##Below the embeddings code, the covered embedding techniques are the following:\n",
        "1. Amplitude embedding.\n",
        "2. Angle embedding.\n",
        "3. IQP embedding.\n",
        "4. QAOA embedding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8J9p3XXT8gJ"
      },
      "source": [
        "###1- Amplitude embedding:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvUFTLDGUZNb"
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev, interface='tf')\n",
        "def circuit(inputs, quantum_weights):\n",
        "\n",
        "    # Apply Amplitude encoding to the input data\n",
        "    qml.AmplitudeEmbedding(features=inputs, wires=range(n_qubits), pad_with=0)\n",
        "\n",
        "\n",
        "    qml.StronglyEntanglingLayers(weights=quantum_weights, wires=range(n_qubits))\n",
        "    #qml.BasicEntanglerLayers(weights=quantum_weights, wires=range(n_qubits))\n",
        "\n",
        "    return [qml.expval(qml.PauliX(i)) for i in range(n_qubits)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2- Angle embedding:\n",
        "\n"
      ],
      "metadata": {
        "id": "JkGtrgw-48Jv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5piC9UcjyHG"
      },
      "outputs": [],
      "source": [
        "#Run this for AngleEmbedding\n",
        "\n",
        "@qml.qnode(dev, interface='tf')\n",
        "def circuit(inputs, quantum_weights):\n",
        "    # Apply AngleEmbedding encoding to the input data\n",
        "    qml.AngleEmbedding(features=inputs, wires=range(n_qubits))\n",
        "\n",
        "    qml.StronglyEntanglingLayers(weights=quantum_weights, wires=range(n_qubits))\n",
        "    #qml.BasicEntanglerLayers(weights=quantum_weights, wires=range(n_qubits))\n",
        "\n",
        "    return [qml.expval(qml.PauliX(i)) for i in range(n_qubits)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3- IQP Embedding:"
      ],
      "metadata": {
        "id": "pth-NE3F5Fhy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZbithZAoSrJ"
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev, inteface='tf')\n",
        "def circuit(inputs, quantum_weights):\n",
        "  # Apply IPQ encoding to the input data\n",
        "\n",
        "  qml.IQPEmbedding(features=inputs, wires=range(n_qubits))\n",
        "\n",
        "  qml.StronglyEntanglingLayers(weights=quantum_weights, wires=range(n_qubits))\n",
        "  #qml.BasicEntanglerLayers(weights=quantum_weights, wires=range(n_qubits))\n",
        "\n",
        "\n",
        "  return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4- QAOA Embedding:"
      ],
      "metadata": {
        "id": "MMhat9lp5NGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rinFC72XaRlP"
      },
      "outputs": [],
      "source": [
        "#shape = qml.QAOAEmbedding.shape(n_layers=2, n_wires=2)\n",
        "#weights = np.random.random(shape)\n",
        "\n",
        "@qml.qnode(dev, interface='tf')\n",
        "def circuit(inputs, weights_0, weights_1):\n",
        "\n",
        "  # Apply QAOA encoding\n",
        "  qml.QAOAEmbedding(features=inputs, weights=weights_0, wires=range(n_qubits))\n",
        "\n",
        "  # Apply StronglyEntanglingLayers\n",
        "  qml.StronglyEntanglerLayers(weights=weights_1, wires=range(n_qubits))\n",
        "  #qml.BasicEntanglerLayers(weights=weights_1, wires=range(n_qubits))\n",
        "\n",
        "  return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_P8dZsDmjEY"
      },
      "source": [
        "\n",
        "\n",
        "### **Training loop**\n",
        "Before excuting this code please make sure that:\n",
        "- The last executed code for the circuit is the bloc is the right one.\n",
        "- That the weights in the loop are configured to the chosen encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cvgw8Dv-eHxv"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pennylane as qml   # Pennylane for quantum computing\n",
        "from pennylane import numpy as np  # Pennylane's version of NumPy\n",
        "import tensorflow as tf   # TensorFlow for neural networks\n",
        "from tensorflow.keras import layers  # Keras layers to define NN\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "from pennylane.templates import StronglyEntanglingLayers\n",
        "\n",
        "\n",
        "# Step 3: Define the number of variational layers and parameters per layer\n",
        "n_layers = 8\n",
        "\n",
        "\n",
        "weight_shapes = {\"quantum_weights\": (n_layers, n_qubits, 3)} # Correct shape for StronglyEntanglingLayers\n",
        "\n",
        "\"\"\"weight_shapes = {\n",
        "   \"weights_0\": qml.QAOAEmbedding.shape(n_layers=n_layers, n_wires=n_qubits),  # QAOAEmbedding shape\n",
        "   \"weights_1\": (n_layers, n_qubits,3)  # BasicEntanglerLayers shape\n",
        "   }\"\"\"\n",
        "\n",
        "\n",
        "print(n_features)\n",
        "# Step 5: Create the full model\n",
        "def create_model():\n",
        "    # Input layer:\n",
        "    inputs = layers.Input(shape=(n_features,))\n",
        "    weight_specse = {\n",
        "    \"weights\": {\n",
        "        \"initializer\": tf.keras.initializers.RandomUniform(minval=-np.pi, maxval=np.pi)  # Custom initializer for rotation angles\n",
        "    }\n",
        "    }\n",
        "\n",
        "    qlayer = qml.qnn.KerasLayer(circuit, weight_shapes, weight_specs=weight_specse,output_dim=n_qubits)\n",
        "\n",
        "\n",
        "    # Dense layer: classical post-processing\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    # Create the Keras model\n",
        "    model = tf.keras.models.Sequential([inputs, qlayer, outputs])\n",
        "    return model\n",
        "\n",
        "# Step 6: Compile the model\n",
        "model = create_model()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 7: Print model summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# To train the model, use the following (assuming you have dataset X_train, y_train):\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=100, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz1Ljrxp1N8A"
      },
      "source": [
        "Basic with angle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFCFnY2s4s7H"
      },
      "source": [
        "\n",
        "\n",
        "### Training loop with metrics\n",
        "* Max entropy\n",
        "\n",
        "Before excuting this code please make sure you excuted the right embedding code block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpmE5uQrnvAr",
        "outputId": "794f7877-c726-444a-f200-b36229037de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install catboost\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from random import shuffle\n",
        "import warnings\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree  import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Turn off the warnings.\n",
        "warnings.filterwarnings(action='ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "def Evaluate(Model_Name, Model_Abb, X_test, Y_test):\n",
        "\n",
        "    Pred_Value_prob= Model_Abb.predict(X_test)\n",
        "    Pred_Value = (Pred_Value_prob > 0.5).astype(int)\n",
        "    Accuracy = metrics.accuracy_score(Y_test,Pred_Value)\n",
        "    Sensitivity = metrics.recall_score(Y_test,Pred_Value)\n",
        "    Precision = metrics.precision_score(Y_test,Pred_Value)\n",
        "    F1_score = metrics.f1_score(Y_test,Pred_Value)\n",
        "    Recall = metrics.recall_score(Y_test,Pred_Value)\n",
        "\n",
        "    print('--------------------------------------------------\\n')\n",
        "    print('The {} Model Accuracy   = {}\\n'.format(Model_Name, np.round(Accuracy,3)))\n",
        "    print('The {} Model Sensitvity = {}\\n'.format(Model_Name, np.round(Sensitivity,3)))\n",
        "    print('The {} Model Precision  = {}\\n'.format(Model_Name, np.round(Precision,3)))\n",
        "    print('The {} Model F1 Score   = {}\\n'.format(Model_Name, np.round(F1_score,3)))\n",
        "    print('The {} Model Recall     = {}\\n'.format(Model_Name, np.round(Recall,3)))\n",
        "    print('--------------------------------------------------\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUxqCKmzn7WF"
      },
      "outputs": [],
      "source": [
        "Evaluate(\"Amplitude Embedding model\", model, X_test, y_test[:2000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeVFABcdGrc5"
      },
      "outputs": [],
      "source": [
        "model.save_weights('/content/drive/MyDrive/Dataset_Quantum/Models/models_weights/weights_amplitude')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}